<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fire'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mosp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfire\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fire'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import fire\n",
    "import json\n",
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl, BitsAndBytesConfig\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    set_peft_model_state_dict\n",
    ")\n",
    "from peft import PeftModel\n",
    "import re\n",
    "import ast\n",
    "\n",
    "device = 'auto' #@param {type: \"string\"}\n",
    "model = 'AIDX-ktds/ktdsbaseLM-v0.12-based-on-openchat3.5' #@param {type: \"string\"}\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "model,\n",
    "quantization_config=bnb_config,\n",
    "#load_in_4bit=True, # Quantization Load\n",
    "device_map=device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "input_text = \"안녕하세요.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"mps\")  # M3 Pro의 GPU 디바이스 설정\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_length=1024)\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2970941341.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    poetry install\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "   poetry install"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minuum-llm-py3.12",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
version https://git-lfs.github.com/spec/v1
oid sha256:7c5aa51276a2f0d6a8f4809ac4c53188e4a66db953cccd11a6e340730c1672cb
size 4178
>>>>>>> e750685f819534bc284978bee07b405d92b7c178
