{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PineconeRetrievalChain 테스트 노트북"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone API Key가 제대로 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if PINECONE_API_KEY:\n",
    "    print(\"Pinecone API Key가 제대로 로드되었습니다.\")\n",
    "else:\n",
    "    print(\"Pinecone API Key가 로드되지 않았습니다. .env 파일을 확인하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 'liberty-rag-json'가 이미 존재합니다.\n",
      "Pinecone 인덱스가 성공적으로 초기화되었습니다: {'index': <pinecone.data.index.Index object at 0x163db8fd0>, 'namespace': 'liberty-rag-json-namespace-01'}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Pinecone 인덱스 생성 및 초기화\n",
    "import pinecone_ as pinecone\n",
    "\n",
    "# 환경 변수 로드 (dotenv 파일 설정이 되어 있어야 합니다)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Pinecone API Key 및 인덱스 이름\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\", \"liberty-rag-json\")\n",
    "\n",
    "# Pinecone 인덱스 초기화\n",
    "retrieval_chain = pinecone.PineconeRetrievalChain(index_name=PINECONE_INDEX_NAME)\n",
    "print(f\"Pinecone 인덱스가 성공적으로 초기화되었습니다: {retrieval_chain.pinecone_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone Index 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Index, init\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME=os.getenv(\"PINECONE_INDEX_NAME\", \"liberty-ai-index\")\n",
    "def create_index(api_key: str=PINECONE_API_KEY, index_name: str=PINECONE_INDEX_NAME, dimension: int = 768, metric: str = \"dotproduct\", host=\"https://liberty-rag-json-hwsbh8f.svc.aped-4627-b74a.pinecone.io\"):\n",
    "    \"\"\"Pinecone 인덱스를 생성하고 반환합니다.\"\"\"\n",
    "    # Pinecone 클라이언트를 API 키로 초기화\n",
    "    #init(api_key=api_key,environment=PINECONE_ENVIRONMENT)\n",
    "    \n",
    "    try:\n",
    "            # 이미 존재하는 인덱스를 가져옴\n",
    "        index = Index(index_name, host=host)\n",
    "        print(f\"인덱스 '{index_name}'가 이미 존재합니다.\")\n",
    "    except Exception as e:\n",
    "        # 인덱스가 존재하지 않으면 새로 생성\n",
    "        print(f\"인덱스 '{index_name}'가 존재하지 않아서 새로 생성합니다.\")\n",
    "        from pinecone import create_index\n",
    "        create_index(\n",
    "                name=index_name,\n",
    "                dimension=dimension,  # 임베딩 차원수 (모델에 맞게 설정)\n",
    "                metric=metric\n",
    "            )\n",
    "        index = Index(index_name, host=host)\n",
    "        print(f\"새로운 인덱스 '{index_name}' 생성 완료\")\n",
    "        \n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #\"\"\"Pinecone 인덱스를 초기화하거나 존재하지 않으면 생성합니다.\"\"\"\n",
    "# host = \"https://liberty-index-hwsbh8f.svc.aped-4627-b74a.pinecone.io\"\n",
    "# index = create_index(api_key=PINECONE_API_KEY, host=host, index_name=PINECONE_INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 이름: {'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'liberty-rag-json-namespace-01': {'vector_count': 57104}},\n",
      " 'total_vector_count': 57104}\n",
      "네임스페이스: liberty-rag-json-namespace-01\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "host = \"https://liberty-rag-json-hwsbh8f.svc.aped-4627-b74a.pinecone.io\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# 인덱스 접근\n",
    "index = pc.Index(host=host)  # describe_index()로 host 확인 가능\n",
    "pinecone_params = {\"index\": index, \"namespace\": PINECONE_INDEX_NAME + \"-namespace-01\"}\n",
    "\n",
    "# 인덱스와 pinecone_params 테스트\n",
    "print(f\"인덱스 이름: {index.describe_index_stats()}\")\n",
    "print(f\"네임스페이스: {pinecone_params['namespace']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 업로드(json loading, split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 63704개 중 63704개의 문서를 로드했습니다.\n",
      "{'book_id': 'LJU000001', 'category': '환경/교통법', 'popularity': 3, 'keyword': ['개발제한구역의 지정 및 관리에 관한 특별조치법', '시정명령', '개발제한구역법', '원심판결을 파기', '도시계획법'], 'word_segment': 832, 'publication_ymd': '20131212'}\n",
      "이행강제금부과처분취소 (대법원 2013. 12. 12. 선고 2012두20397 판결) 【출전】 판례공보 제434호, 2014년 1월 15일 193페이지 【판시사항】 [1] 개발제한구역의 지정 및 관리에 관한 특별조치법상 이행강제금을 부과·징수할 때마다 그에 앞서 시정명령 절차를 다시 거쳐야 하는지 여부(소극) [2] 개발제한구역의 지정 및 관리에 관한 특별조치법에 의한 이행강제금 부과의 근거가 되는 시정명령이 이루어져야 하는 시기(=법률 시행일인 2010. 2. 7. 이후) 【판결요지】 [1] 개발제한구역의 지정 및 관리에 관한 특별조치법 제30조 제1항, 제30조의2 제1항 및 제2항의 규정에 의하면 시정명령을 받은 후 그 시정명령의 이행을 하지 아니한 자에 대하여 이행강제금을 부과할 수 있고, 이행강제금을 부과하기 전에 상당한 기간을 정하여 그 기한까지 이행되지 아니할 때에 이행강제금을 부과·징수한다는 뜻을 문서로 계고하여야 하므로, 이행강제금의 부과·징수를 위한 계고는 시정명령을 불이행한 경우에 취할 수 있는 절차라 할 것이고, 따라서 이행강제금을 부과·징수할 때마다 그에 앞서 시정명령 절차를 다시 거쳐야 할 필요는 없다. [2] 구 개발제한구역의 지정 및 관리에 관한 특별조치법(2009. 2. 6. 법률 제9436호로 개정되기 전의 것)이나 개발제한구역의 지정 및 관리에 관한 특별조치법(이하 '개발제한구역법'이라 한다)이 제정·시행되기 전의 구 도시계획법(2000. 1. 28. 법률 제6243호로 전부 개정되기 전의 것)은 개발제한구역에서 행위제한을 위반한 자에 대한 시정명령을 정하고 있을 뿐이었으나, 2009. 2. 6. 법률 제9436호로 개발제한구역법을 개정하면서 시정명령을 이행하지 아니한 자에 대한 이행강제금을 정한 개발제한구역법 제30조의2를 신설하는 한편 그 이행강제금 부과의 근거가 되는 시정명령에 관한 제30조를 개정하였는데, 건축물·공작물 등의 철거·폐쇄·개축 또는 이전에 관하여는 시정명령의 요건이나 내용이 변경되었을 뿐만 아니라 종전 규정과 달리 '상당한 기간을 정하여' 시정명령을 하도록 하였다. 그리고 위 법률 부칙은 제1조에서 \"이 법은 공포 후 6개월이 경과한 날부터 시행한다. 다만, 제30조 및 제30조의2의 개정규정은 공포 후 1년이 경과한 날부터 시행한다.\"고 규정하여 신설된 이행강제금 규정과 그 이행강제금 부과의 근거가 되는 시정명령에 관한 개정규정이 2010. 2. 7. 함께 시행되도록 하고 있으며, 달리 개정 법률 시행 당시 종전의 규정에 따라 이루어진 시정명령 등에 관한 일반적인 경과조치 규정을 두고 있지 않다. 위와 같은 개발제한구역법의 개정 경과 및 규정 내용 등에 비추어 보면, 개발제한구역법에 의한 이행강제금 부과의 근거가 되는 시정명령은 위 법률 시행일인 2010. 2. 7. 이후에 이루어져야 한다. 【참조조문】 [1] 개발제한구역의 지정 및 관리에 관한 특별조치법 제30조 제1항, 제30조의2제1항, 제2항 [2] 개발제한구역의 지정 및 관리에 관한 특별조치법 제30조 제1항, 제30조의2제1항, 부칙(2009.2.6.)제1조 구 도시계획법(2000.1.28. 법률 제6243호로 전부개정되기 전의 것)제4조 제5항 【원심판결】 부산고법 2012.8.22. 선고 2012누379판결 【주문】 원심판결을 파기하고, 사건을 부산고등법원으로 환송한다. 【이유】 상고이유를 판단한다. 1. 개발제한구역의 지정 및 관리에 관한 특별조치법(이하 '개발제한구역법'이라 한다)제30조 제1항, 제30조의2제1항 및 제2항의 규정에 의하면 시정명령을 받은 후 그 시정명령의 이행을 하지 아니한 자에 대하여 이행강제금을 부과할 수 있고, 그 이행강제금을 부과하기 전에 상당한 기간을 정하여 그 기한까지 이행되지 아니할 때에 이행강제금을 부과·징수한다는 뜻을 문서로 계고하여야 하므로, 이행강제금의 부과·징수를 위한 계고는 시정명령을 불이행한 경우에 취할 수 있는 절차라 할 것이고, 따라서 이행강제금을 부과·징수할 때마다 그에 앞서 시정명령 절차를 다시 거쳐야 할 필요는 없다고 보아야 한다. 한편 구 개발제한구역법(2009.2.6. 법률 제9436호로 개정되기 전의 것)이나 개발제한구역법이 제정·시행되기 전의 구 도시계획법(2000.1.28. 법률 제6243호로 전부 개정되기 전의 것, 이하 같다)은 개발제한구역에서의 행위제한을 위반한 자에 대한 시정명령을 정하고 있을 뿐이었으나, 2009.2.6. 법률 제9436호로 개발제한구역법을 개정하면서 시정명령을 이행하지 아니한 자에 대한 이행강제금을 정한 개발제한구역법 제30조의2를 신설하는 한편 그 이행강제금 부과의 근거가 되는 시정명령에 관한 제30조를 개정하였는데, 건축물·공작물 등의 철거·폐쇄·개축 또는 이전에 관하여는 시정명령의 요건이나 내용이 변경되었을 뿐만 아니라 종전의 규정과 달리 '상당한 기간을 정하여'시정명령을 하도록 하였다. 그리고 위 법률 부칙은 제1조에서 \"이 법은 공포 후 6개월이 경과한 날부터 시행한다. 다만, 제30조 및 제30조의2의 개정규정은 공포 후 1년이 경과한 날부터 시행한다.\"고 규정하여 신설된 이행강제금 규정과 그 이행강제금 부과의 근거가 되는 시정명령에 관한 개정규정이 2010.2.7. 함께 시행되도록 하고 있으며, 달리 개정 법률 시행 당시 종전의 규정에 따라 이루어진 시정명령 등에 관한 일반적인 경과조치 규정을 두고 있지 않다. 위와 같은 개발제한구역법의 개정 경과 및 규정 내용 등에 비추어 보면, 개발제한구역법에 의한 이행강제금 부과의 근거가 되는 시정명령은 위 법률 시행일인 2010.2.7. 이후에 이루어져야 한다. 2. 원심은, 판시와 같은 사정에 비추어 보면 ① 피고가 2000.4.28. 원고에게 보낸 '개발제한구역 내 불법행위 원상복구 계고'라는 제목의 문서는 개발제한구역법 제30조 제1항에서 정하고 있는 시정명령에 해당하고, ② 피고가 2010.10.18. 원고에게 보낸 '2010. 정기분이행강제금 시정명령 및 부과예고 처분'이라는 제목의 문서는 개발제한구역법 제30조의2제2항에 따른 계고로 보아야 하므로, 피고의 이 사건 이행강제금 부과는 적법한 절차를 거쳐 이루어진 것이라고 판단하여, 그 취소를 명한 제1심판결을 취소하고 원고의 청구를 기각하는 판결을 선고하였다. 3. 원심판결 이유를 앞서 본 법리에 비추어 살펴보면, 원심이 이 사건 이행강제금 부과의 근거가 되는 시정명령으로 들고 있는 위 2000.4.28. 자 문서는 구 도시계획법에 따라 이루어진 것에 불과하여 개발제한구역법 제30조의2제1항이 정한 '제30조 제1항에 따른 시정명령'에 해당한다고 보기 어렵고, 원심판결 이유 및 기록에 비추어 보아도 피고가 2010.2.7. 부터 위 2010.10.18. 자 문서를 보내기까지 사이에 피고에게 시정명령을 하였다는 사정은 나타나 있지 않다. 그렇다면 위 2010.10.18. 자 문서에 의한 계고 및 그에 기초한 이 사건 이행강제금 부과는 그 근거가 될 수 있는 적법한 시정명령 절차를 거치지 않고 이루어진 것으로서 위법하다 할 것이다. 따라서 이와 결론을 달리한 원심의 판단에는 상고이유 주장과 같이 이행강제금 부과에 필요한 시정명령의 요건에 관한 법리를 오해하여 판결에 영향을 미친 위법이 있다. 4. 결론 그러므로 원심판결을 파기하고, 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\n",
      "LJU000001\n",
      "환경/교통법\n",
      "3\n",
      "['개발제한구역의 지정 및 관리에 관한 특별조치법', '시정명령', '개발제한구역법', '원심판결을 파기', '도시계획법']\n",
      "832\n",
      "20131212\n"
     ]
    }
   ],
   "source": [
    "# Test 2: 문서 로드 및 전처리 테스트\n",
    "import pinecone_\n",
    "import os\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_dir = \"data/154.의료, 법률 전문 서적 말뭉치/01-1.정식개방데이터/Training/02.라벨링데이터/Training_legal.json\"  # data 폴더에 PDF 파일들을 저장해 주세요\n",
    "import json\n",
    "split_docs=[]\n",
    "with open(data_dir, 'r', encoding='utf-8') as f:\n",
    "    try:\n",
    "        json_data = json.load(f)\n",
    "                    \n",
    "        # data 배열에서 문서 추출 (처음 10개만)\n",
    "        if isinstance(json_data, dict) and 'data' in json_data:\n",
    "            for item in json_data['data']:  # 처음 10개의 문서만 로드\n",
    "                if isinstance(item, dict):\n",
    "                    # Document 객체 생성\n",
    "                    from langchain.schema import Document\n",
    "                    doc = Document(\n",
    "                        page_content=item.get('text', ''),\n",
    "                        metadata={\n",
    "                            'book_id': item.get('book_id'),\n",
    "                            'category': item.get('category'),\n",
    "                            'popularity': item.get('popularity'),\n",
    "                            'keyword': item.get('keyword', []),\n",
    "                            'word_segment': item.get('word_segment', []),\n",
    "                            'publication_ymd': item.get('publication_ymd')\n",
    "                        }\n",
    "                    )\n",
    "                    split_docs.append(doc)\n",
    "                else:\n",
    "                    print(\"JSON 데이터가 예상된 형식이 아닙니다.\")\n",
    "                    print(\"데이터 구조:\", json_data.keys() if isinstance(json_data, dict) else type(json_data))\n",
    "            \n",
    "            print(f\"전체 {len(json_data['data'])}개 중 {len(split_docs)}개의 문서를 로드했습니다.\")\n",
    "                        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON 파일 파싱 중 오류가 발생했습니다: {e}\")\n",
    "print(split_docs[0].metadata)\n",
    "print(split_docs[0].page_content)\n",
    "print(split_docs[0].metadata['book_id'])\n",
    "print(split_docs[0].metadata['category'])\n",
    "print(split_docs[0].metadata['popularity'])\n",
    "print(split_docs[0].metadata['keyword'])\n",
    "print(split_docs[0].metadata['word_segment'])\n",
    "print(split_docs[0].metadata['publication_ymd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "from tqdm import tqdm\n",
    "def preprocess_documents(\n",
    "    split_docs: List[Any], \n",
    "    metadata_keys: List[str] = [\"book_id\", \"category\", \"popularity\", \"keyword\", \"word_segment\", \"publication_ymd\"], \n",
    "    min_length: int = 5\n",
    "):\n",
    "    \"\"\"문서를 전처리하고 내용과 메타데이터를 반환합니다.\"\"\"\n",
    "    contents = []\n",
    "    metadatas = {key: [] for key in metadata_keys}\n",
    "    \n",
    "    for doc in tqdm(split_docs, desc=\"문서 전처리 중\"):\n",
    "        content = doc.page_content.strip()\n",
    "        if content and len(content) >= min_length:\n",
    "            # 컨텍스트 길이 제한 (Pinecone 권장사항)\n",
    "            contents.append(content[:4000])  \n",
    "            \n",
    "            # 메타데이터 추출\n",
    "            for k in metadata_keys:\n",
    "                value = doc.metadata.get(k)\n",
    "                metadatas[k].append(value)\n",
    "                \n",
    "    print(f\"전체 {len(split_docs)}개 중 {len(contents)}개의 문서가 전처리되었습니다.\")\n",
    "    return contents, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "문서 전처리 중: 100%|██████████| 63704/63704 [00:00<00:00, 182826.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 63704개 중 63704개의 문서가 전처리되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "contents, metadatas = preprocess_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_teddynote.korean import stopwords\n",
    "\n",
    "# 한글 불용어 사전 불러오기 (불용어 사전 출처: https://www.ranks.nl/stopwords/korean)\n",
    "stopword = stopwords()\n",
    "#stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import (\n",
    "    create_sparse_encoder,\n",
    "    fit_sparse_encoder,\n",
    ")\n",
    "\n",
    "# 한글 불용어 사전 + Kiwi 형태소 분석기를 사용합니다.\n",
    "sparse_encoder = create_sparse_encoder(stopwords(), mode=\"kiwi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034d74fd39044d8abc58bb7fa0a1d231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sparse Encoder 를 사용하여 contents 를 학습\n",
    "saved_path = fit_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_sparse_encoder]\n",
      "Loaded Sparse Encoder from: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "# 추후에 학습된 sparse encoder 를 불러올 때 사용합니다.\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiBM25Tokenizer\n",
    "passage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-query\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Sparse Encoder 학습 및 로드 \n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import secrets\n",
    "import itertools\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Index, init, Pinecone\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from typing import List, Dict, Any\n",
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiBM25Tokenizer\n",
    "def generate_hash() -> str:\n",
    "    \"\"\"24자리 무작위 hex 값을 생성하고 6자리씩 나누어 '-'로 연결합니다.\"\"\"\n",
    "    random_hex = secrets.token_hex(12)\n",
    "    return \"-\".join(random_hex[i: i + 6] for i in range(0, 24, 6))\n",
    "\n",
    "from pinecone import Index, init\n",
    "import itertools\n",
    "def chunks(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    chunk = list(itertools.islice(it, size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = list(itertools.islice(it, size))\n",
    "\n",
    "# def upsert_documents_parallel(contents, metadatas, sparse_encoder, pinecone_params, embedder=UpstageEmbeddings(model=\"solar-embedding-1-large-query\"), batch_size=100, max_workers=30):\n",
    "#     # 문자열을 Document 객체로 변환\n",
    "from langchain.schema import Document\n",
    "keys = list(metadatas.keys())\n",
    "embedder=passage_embeddings\n",
    "    \n",
    "    # documents = [\n",
    "    #     Document(\n",
    "    #         page_content=text,\n",
    "    #         metadata={\n",
    "    #             'book_id': metadatas['book_id'][i],\n",
    "    #             'category': metadatas['category'][i], \n",
    "    #             'popularity': metadatas['popularity'][i],\n",
    "    #             'keyword': metadatas['keyword'][i],\n",
    "    #             'word_segment': metadatas['word_segment'][i],\n",
    "    #             'publication_ymd': metadatas['publication_ymd'][i]\n",
    "    #         }\n",
    "    #     ) for i, text in enumerate(batch)\n",
    "    # ]\n",
    "\n",
    "def process_batch(batch, contents, metadatas, sparse_encoder, passage_embeddings, pinecone_params):\n",
    "    \"\"\"\n",
    "    배치 단위로 문서를 처리하여 Pinecone에 업로드합니다.\n",
    "    \n",
    "    Args:\n",
    "        batch: 현재 처리할 문서들의 인덱스 리스트\n",
    "        contents: 전체 문서 내용 리스트\n",
    "        metadatas: 전체 문서의 메타데이터 딕셔너리\n",
    "        sparse_encoder: 희소 임베딩을 생성하는 인코더\n",
    "        passage_embeddings: 밀집 임베딩을 생성하는 인코더\n",
    "        pinecone_params: Pinecone 관련 설정\n",
    "    \"\"\"\n",
    "    # 현재 배치에 해당하는 문서와 메타데이터 추출\n",
    "    context_batch = [contents[i] for i in batch]\n",
    "    metadata_keys = ['book_id', 'category', 'popularity', 'keyword', 'word_segment', 'publication_ymd']\n",
    "    \n",
    "    batch_result = [\n",
    "        {\n",
    "            \"context\": context[:1000],  # 컨텍스트 길이 제한\n",
    "            **{key: metadatas[key][i] for key in metadata_keys}\n",
    "        } for i, context in enumerate(context_batch)\n",
    "    ]\n",
    "\n",
    "    ids = [generate_hash() for _ in range(len(batch))]\n",
    "    dense_embeds = passage_embeddings.embed_documents(context_batch)\n",
    "    sparse_embeds = sparse_encoder.encode_documents(context_batch)\n",
    "    print(f\"Processing batch: {batch}\")\n",
    "    vectors = [\n",
    "        {\n",
    "            \"id\": id_,\n",
    "            \"values\": dense_embed,\n",
    "            \"sparse_values\": sparse_embed,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        for id_, dense_embed, sparse_embed, metadata in zip(\n",
    "            ids, dense_embeds, sparse_embeds, batch_result\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        return index.upsert(\n",
    "            vectors=vectors,\n",
    "            namespace=pinecone_params[\"namespace\"],\n",
    "            async_req=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Upsert 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5effbc5df284108882ad810dc98bff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "문서 Upsert 중: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 0개의 Vector가 Upsert 되었습니다.\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'liberty-rag-json-namespace-01': {'vector_count': 57004}},\n",
      " 'total_vector_count': 57004}\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "max_workers=30\n",
    "# 57,005번째 문서부터 처리\n",
    "start_idx = 57005\n",
    "contents_subset = contents[start_idx:]\n",
    "metadata_subset = {key: values[start_idx:] for key, values in metadatas.items()}\n",
    "\n",
    "batches = list(chunks(range(len(contents_subset)), batch_size))\n",
    "print(batches)\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            process_batch, \n",
    "            batch,\n",
    "            contents_subset,\n",
    "            metadata_subset,\n",
    "            sparse_encoder,\n",
    "            passage_embeddings,\n",
    "            pinecone_params\n",
    "        ) for batch in batches\n",
    "    ]\n",
    "    print(futures)\n",
    "    results = []\n",
    "    \n",
    "    # tqdm 설정 추가\n",
    "    total_docs = len(contents_subset)\n",
    "    pbar = tqdm(total=total_docs, desc=\"문서 Upsert 중\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    processed_docs = 0\n",
    "    for idx, future in enumerate(as_completed(futures)):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "        # 진행률과 예상 시간 계산\n",
    "        elapsed_time = time.time() - start_time\n",
    "        processed_docs += len(batches[idx])\n",
    "        progress = processed_docs / total_docs\n",
    "        estimated_total_time = elapsed_time / progress if progress > 0 else 0\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "        \n",
    "        # 진행 상태 업데이트\n",
    "        pbar.set_postfix({\n",
    "            'progress': f'{processed_docs}/{total_docs}',\n",
    "            'remaining': f'{remaining_time:.1f}s'\n",
    "        })\n",
    "        pbar.update(len(batches[idx]))\n",
    "    \n",
    "    pbar.close()\n",
    "    total_upserted = sum(result.upserted_count for result in results if result)\n",
    "    print(f\"총 {total_upserted}개의 Vector가 Upsert 되었습니다.\")\n",
    "    print(f\"{pinecone_params['index'].describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents subset length: 700\n",
      "Metadata subset length: 6\n",
      "Number of batches: 7\n",
      "Number of futures: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: [400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "Processing batch: [600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "문서 Upsert 중:  14%|█▍        | 100/700 [01:03<06:06,  1.64it/s, progress=200/700, remaining=156.2s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "Processing batch: [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 Upsert 중:  71%|███████▏  | 500/700 [01:18<00:18, 10.79it/s, progress=500/700, remaining=31.1s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: [500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "문서 Upsert 중: 100%|██████████| 700/700 [01:20<00:00,  8.67it/s, progress=700/700, remaining=0.0s]\n"
     ]
    }
   ],
   "source": [
    "# 57,005번째 문서부터 처리하기 위한 데이터 슬라이싱\n",
    "start_idx = min(63004, len(contents))\n",
    "contents_subset = contents[start_idx:]\n",
    "metadata_subset = {key: values[start_idx:] for key, values in metadatas.items()}\n",
    "print(f\"Contents subset length: {len(contents_subset)}\")\n",
    "print(f\"Metadata subset length: {len(metadata_subset)}\")\n",
    "batch_size = 100\n",
    "max_workers = 30\n",
    "\n",
    "# 배치 생성\n",
    "batches = list(chunks(range(len(contents_subset)), batch_size))\n",
    "print(f\"Number of batches: {len(batches)}\")\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            process_batch, \n",
    "            batch,\n",
    "            contents_subset,  # 슬라이싱된 contents 사용\n",
    "            metadata_subset,  # 슬라이싱된 metadata 사용\n",
    "            sparse_encoder,\n",
    "            passage_embeddings,\n",
    "            pinecone_params\n",
    "        ) for batch in batches\n",
    "    ]\n",
    "    print(f\"Number of futures: {len(futures)}\")\n",
    "    # 진행 상황 모니터링\n",
    "    total_docs = len(contents_subset)\n",
    "    pbar = tqdm(total=total_docs, desc=\"문서 Upsert 중\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = []\n",
    "    processed_docs = 0\n",
    "    \n",
    "    for idx, future in enumerate(as_completed(futures)):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "        processed_docs += len(batches[idx])\n",
    "        elapsed_time = time.time() - start_time\n",
    "        progress = processed_docs / total_docs\n",
    "        estimated_total_time = elapsed_time / progress if progress > 0 else 0\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "           \n",
    "        pbar.set_postfix({\n",
    "            'progress': f'{processed_docs}/{total_docs}',\n",
    "            'remaining': f'{remaining_time:.1f}s'\n",
    "        })\n",
    "        pbar.update(len(batches[idx]))\n",
    "    \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "# 검색기 생성\n",
    "pinecone_params = {\"index\": index, \"namespace\": PINECONE_INDEX_NAME + \"-namespace-01\",\"embeddings\" :UpstageEmbeddings(model=\"solar-embedding-1-large-query\"),\"sparse_encoder\":sparse_encoder}\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종합소득세부과처분취소 (대법원 2013. 8. 22. 선고 2011두17769 판결) 【출전】 판례공보 제426호, 2013년 9월 15일 1710페이지 【판시사항】 부동산 임대사업자가 자금을 차입하여 임대사업용 부동산을 취득하였으나 그 부동산으로부터 당해 연도에 임대수입을 얻지 못한 경우, 부동산 임대소득을 계산할 때 차입금에 대한 부동산 취득일 다음날부터 지급이자를 당해 연도의 필요경비에 산입하여야 하는지 여부(원칙적 적극) 【판결요지】 부동산 임대사업용 고정자산의 매입 등에 소요된 차입금에 대한 지급이자 중에서 그 취득일까지 지출된 금액은 당해 연도의 부동산 임대소득을 계산함에 있어서는 필요경비로 불산입하는 대신 이를 자본적 지출로 보아 원가에 산입하여 나중에 그 사업용 자산을 양도할 때 비용으로 인정하지만, 취득일 후에 남은 차입금에 대한 지급이자는 각 연도의 필요경비로 산입하도록 하고 있다[구 소득세법(2006. 12. 30. 법률 제8144호로 개정되기 전의 것) 제33조 제1항 제10호, 구 소득세법 시행령(2008. 2. 29. 대통령령 제20720호로 개정되기 전의 것) 제75조 제1·2·5항]. 한편 소득세법상의 소득금액은 사업소득별로 통산하여 산정하는 것이므로, 부동산 임대사업자가 복수의 부동산을 각각 별도로 사업자등록을 한 임대사업에 제공한 경우에도 그 사업자의 연도별 부동산임대소득 및 필요경비는 각 사업장의 수입금액과 필요경비를 통산하여 산정하여야 한다. 따라서 그 복수의 부동산 임대사업장 중 수입은 없고 필요경비만 발생한 사업장이 있는 경우에도 그 사업장의 필요경비를 당해 연도의 총 부동산임대소득의 계산에서 제외할 것은 아니다. 위와 같은 법령 규정의 내용과 법리에 비추어 보면, 부동산 임대사업자가 자금을 차입하여 임대사업용 부동산을 취득한 경우 그 차입금에 대한 부동산 취득일 다음날부터의 지급이자는 비록 그 부동산으로부터 당해 연도에 임대수입을 얻지 못하였다고 하더라도, 이를 개인적 용도로 전환하여 사용하였다는 등 특별한 사정이 없는\n",
      "{'page': None, 'source': None, 'score': 0.603655338}\n",
      "\n",
      "====================\n",
      "\n",
      "3) 프로젝트 파이낸스의 특징(1) 특징프로젝트 파이낸스의 가장 두드러진 특징은 차주는 신설회사인 프로젝트 컴퍼니이며, 금융기관은 사업주에 대해 대출금 상환청구 내지는 구상청구를 할 수 없다는 것이다. 이에 따라 프로젝트 파이낸스는 사업주가 위험부담을 기피하는 대규모 프로젝트에 대한 자금조달수단으로 많이 이용되고 있다. 종래의 기업금융(corporate finance)과의 주된 차이점은 다음과 같다.ⅰ) 기업금융은 신용도가 있는 기존 기업에 대한 대출로서 기업의 용도를 바탕으로 대출이 이루어지는 반면, 프로젝트 파이낸스는 신용도가 없는 신설회사에 대한 대출로서 상환의 주재원은 당해 프로젝트의 미래 현금흐름이다. 따라서 프로젝트가 실패하여도 사업주에 대한 상환청구권이 없거나 제한되어, 자금을 공여하는 금융기관에게는 리스크가 매우 높다.ⅱ) 기업금융에서는 사업주가 대출금의 상환의무를 부담하지만, 프로젝트 파이낸스에서는 프로젝트 컴퍼니가 차주로서 원리금상환의무를 부담한다. 따라서 프로젝트 컴퍼니의 차입금은 사업주의 대차대조표상 부외(Off Balance)채무로 표시되거나 아예 표시되지 않으므로, 사업주의 재무제표는 악화되지 않는다.ⅲ) 기업금융에서는 사업주가 차주가 되어 대출금의 상환의무를 부담하게 되거나 차주가 지급보증을 하게 되어 사업주에게 이행을 청구할 수 있다. 그러나 프로젝트 파이낸스에서는 사업주는 차주도 아니며, 대출에 대한 보증도 하지 않으므로 사업주에게 상한청구권을 행사할 수 없다.ⅳ) 프로젝트 파이낸스는 기업금융에 비해서 대출금이 대규모이다. 이에 따라 당해 소요자금을 용이하게 조달하기 위하여 컨소시움(consortium)을 구성하고, 대주인 금융기관은 자금부담 및 위험분산 차원에서 단독대출(single loan) 보다는 신디케이티 드론(syndicated loan)을 통해 자금을 공여하는 경우가 많다.ⅴ) 기업금융에 비해서 프로젝트 파이낸스에는 다수의 당사자가 참여하고 그 구조가 복잡하기 때문에 준비에 상당한 시간이 소요되며, 프로젝트의 객관성 및\n",
      "{'page': None, 'source': None, 'score': 0.588502169}\n",
      "\n",
      "====================\n",
      "\n",
      "3) 기금의 관리·운용 등기금은 공사가 관리·운용한다(법41①). 기금은 ⅰ) 금융회사등의 부실채권 및 대통령령으로 정하는 부실징후기업의 자구계획대상자산(영37①: 인수금액이 50억 원 이상인 자구계획대상자산으로서 업무방법서에서 정하는 기준에 해당하는 것)의 인수에 드는 자금(다만, 부실징후기업의 자구계획대상자산의 인수에 드는 자금의 연간 규모는 금융회사등의 부실채권 인수에 드는 자금의 연간 규모를 초과할 수 없다)(제1호), ⅱ) 한국은행으로부터의 차입금 및 한국은행 외의 자로부터의 차입금의 원리금 상환(제2호), ⅲ) 채권의 원리금 상환(제3호), ⅳ) 공사가 제26조 제1항 제3호·제7호·제12호 및 제13호의 업무를 수행하는 데에 드는 자금의 대여(제4호), ⅴ) 공적자금상환기금법 제4조 제3항에 따라 체결된 약정의 이행(제5호), ⅵ) 기금의 관리·운용 경비와 그 밖에 기금의 운영에 필요한 비용(제6호)으로 사용한다(법41② 본문). 다만, 부실채권정리기금채권의 발행으로 조성한 자금 및 기금운용수익(부실채권 및 자구계획대상자산의 정리에 따른 수입금을 포함) 중 부실채권의 정리에 따른 수입금은 제4호의 용도로는 사용하지 못한다(법41② 단서).공사는 기금의 여유자금이 있을 때에는 금융회사등에의 예치, 국채·지방채의 매입 또는 정부나 금융회사등이 지급을 보증한 유가증권의 매입, 그 밖에 위원회가 정하는 방법(법35)으로 운용할 수 있다(법41③).(마) 구조조정기금1) 기금의 설치 및 재원금융회사등이 보유하고 있는 부실자산, 부실징후기업 및 구조개선기업이 보유하고 있는 자산의 효율적인 인수정리 등을 위하여 공사에 구조조정기금을 둔다(법43의2). 구조조정기금은 ⅰ) 금융회사등의 출연금(제1호), ⅱ) 공사로부터의 전입금(제2호), ⅲ) 정부의 출연금(제3호), ⅳ) 구조조정기금채권의 발행으로 조성한 자금(제4호), ⅴ) 한국은행으로부터의 차입금(제5호), ⅵ) 한국은행 외의 자로부터의 차입금(제6호), ⅶ) 구조조정기금의 운용수익(부실자산 등의 정리에 따\n",
      "{'page': None, 'source': None, 'score': 0.588267922}\n",
      "\n",
      "====================\n",
      "\n",
      "(ii) 합리적으로 이용 가능한 범위 내에서 필요한 정보를 충분히 수집․ 조사하고 검토하는 절차를 거칠 것의 요건과 관련하여 보면, 그 동안 경영판단의 원칙이 배제된 사건의 상당 수가 이러한 요건을 갖추기 못한 경우가 대부분이다. 즉 관계회사 상호 간의 자금지원(유상증자 참여, 대여)이 문제된 대부분의 사건은, 관계회사의 이사가 이러한 과정을 거쳐 이사회 결의를 통하여 자금지원을 의결한 것이 아니라, 단순히 회사의 경영상의 부담에도 불구하고 관계회사의 부도 등을 방지하는 것이 회사의 신인도를 유지하고 회사의 영업에 이익이 될 것이라는 일반적 ․ 추상적인 기대 하에 자금지원을 한 경우였다. 이와 대비되는 사건이 대판2005. 10. 28. 2003다69638(삼성전자의 이천전기 인수사건)이다. 위 사건에서 대법원은 “이사가 회사의 자산을 인수함에 있어서 그 인수 여부나 거래가액을 결정하는 데에 필요한 정보를 합리적인 정도로 수집하여 충분히 검토를 한 다음 회사의 이익에 합당한 상당성 있는 판단을 하였다면 회사에 대하여 선량한 관리자의 주의 의무를 다한 것이라고 할 것이다”라고 판시하면서 이천전기 인수로 인하여 삼성전자에게 1,904억 원의 손해를 입히는 결과를 초래한 삼성전자 이사들의 손해배상책임을 부정하였다. (iii) 수집 ․ 조사 ․ 검토한 자료를 근거로 회사의 최대 이익에 부합한다고 합리적으로 신뢰하고 신의성실에 따라 경영상의 판단을 내릴 것이라는 요건은, 위 (ii)의 요건을 갖추지 못하는 한 원칙적으로 충족하기 어렵게 될 것이다. (iv) 그 내용이 현저히 불합리하지 않은 것으로서 통상의 이사를 기준으로 할 때 합리적으로 선택할 수 있는 범위 안에 있을 것이라는 요건은, 경영판단의 내용에 관한 것으로서 위 (i) 내지 (iii)의 요건을 충족한다면 법원이 사후적 고찰에 의하여 이사의 경영판단에 관하여 현저한 불합리성을 쉽게 인정하지는 않을 것으로 보인다. 그 동안 관계회사에 대한 자금지원 행위가 배임죄로 기소된 형사사건 등에서 이를 유죄로 인정하는 것\n",
      "{'page': None, 'source': None, 'score': 0.581535935}\n",
      "\n",
      "====================\n",
      "\n",
      "플랜트수출에서 공급자신용의 일반적인 진행절차를 살펴보면 다음과 같다.(1) 수출자와 수입자는 플랜트수출계약을 체결하며, 결제조건은 연불조건으로 산업설비의 제작에 필요한 자금은 수출자가 조달해야 한다.(2) 수출자는 플랜트수출에 필요한 자금을 자신의 신용으로 금융기관으로부터 차입한다. 상환조건은 플랜트수출의 연불결제조건과 일치시킨다.(3) 수출자는 금융기관으로부터 차입한 자금을 이용하여 산업설비를 제작·설치·시공한다.(4) 산업설비 시공완료 후에 수입자는 수출계약상의 조건에 따라 수출자앞 연불로 결제한다.(5) 수출자는 수입자로부터 플랜트수출대금을 연불로 결제 받으면 동 대금으로 금융기관앞 차입금을 상환한다. 그러나 실제로는 수입자가 직접 금융기관앞으로 연불결제대금을 송금토록 한다.3) 구매자신용구매자신용(buyer credit)이란, 공급자의 계약이행에 필요한 자금을 구매자(buyer, 수입자)가 자신의 신용으로 조달하는 금융조달방법으로 중장기신용조건으로 추진되는 자본재 또는 프로젝트에서 주로 이용된다. 따라서 매매계약에서는 목적물의 제작에 필요한 자금을 매수인이 조달하고, 도급계약에서는 일의 완성에 필요에 자금을 도급인이 조달한다.플랜트수출에서는 플랜트수출이행에 필요한 자금을 수입자가 자신의 신용으로 금융기관으로부터 차입하여 수출자에게 현찰로 지급하거나 기성단계별로 지급하고, 플랜트수출이행이 완료되면 이를 운영하여 발생한 수익으로 금융기관앞 차입금을 상환한다. 구매자신용의 특징은 산업설비 운영에서 수익금이 발생하지 않는다고 해도 수입자는 금융기관앞으로 위 차입금을 상환해야 하며, 차주인 수입자가 수출계약과 무관하게 구매자신용의 모든 대출금을 상환해야 한다는 것이다. 따라서 수출자가 계약을 제대로 이행하지 못하는 경우에도 차주는 대출금을 상환해야 하며, 이를 사유로 대출금의 상환을 거절할 수 없다. 금융기관의 대출을 담보하기 위해 수출국에 소재하고 있는 수출신용기관은 이러한 금융거래에 대해 자금을 공여하는 금융기관앞으로 수출보험(또는 수출신용보증)을 제공한다.\n",
      "{'page': None, 'source': None, 'score': 0.580292702}\n",
      "\n",
      "====================\n",
      "\n",
      "규모금액산출 표1. 규모금액의 산출 가. 대상 회계연도 말의 자산총계 : 억원나. 대상 회계연도의 매출액 (*1) : 억원다. 회사의 규모조정계수 적용 전 규모금액 (*2) : 억원라. “라” 금액에 상응하는 규모조정계수 :마. 규모금액[다(가 또는 나)÷라] : 원(*1) 금융기관, 서비스업종 등의 경우에는 영업수익을 매출액으로 보며, 대상기간이 분·반기인 경우 원칙적으로 분·반기매출액을 연간으로 환산하여 사용할 수 있다.(*2) “규모금액”은 위법행위 유형별로 아래 ①부터 ④까지의 구분에 따라 산정한다. 완전자본잠식회사의 경우 아래에서 자산총계를 부채총계로 보며, ①에 해당되면서 ② 또는 ③에도 해당하는 D유형의 경우, ①을 ②, ③보다 우선하여 적용한다.① 아래 항목에 대해서는 심사·감리대상이 되는 회계기간의 기말 자산총계와 매출액을 평균한 금액을 규모금액으로 한다.㉮ A, C유형 전체㉯ B유형 중 영업활동으로 인한 현금흐름의 과대·과소계상㉰ D유형 중 다음의 주석기재사항-타인을 위한 담보제공, 질권 설정, 지급 보증 등으로 인하여 발생가능한 자산의 사용이나 처분의 제한 또는 우발부채로서 관련 채무잔액의 130%초과금액-자신을 위한 담보제공, 질권설정, 지급보증 등과 관련한 금액㉱ ②~③에 해당되지 아니하는 기타 D유형 사항② 아래의 항목에 대해서는 심사·감리대상이 되는 회계기간의 기말 자산총계를 규모금액으로 한다.㉮ B유형 중 자산·부채의 과대·과소계상, 유동·비유동항목간 계정과목 분류 사항㉯ D유형 중 자산·부채와 관련한 계정과목 분류 및 주석기재사항③ 아래 항목에 대해서는 심사·감리대상이 되는 회계기간의 매출액을 규모금액으로 한다.㉮ B유형 중 수익·비용의 과대·과소계상, 영업·비영업손익간 계정과목 분류 사항㉯ D유형 중 수익·비용과 관련한 계정과목 분류 및 주석기재사항④ 직전 사업연도말 자산총계가 1,000억원 미만인 비상장법인으로서 (*3).각 호 중 어느 하나에도 해당하지 아니하는 회사는 매출액이 자산총계의 30% 미만이더라도 자산총계의 30%\n",
      "{'page': None, 'source': None, 'score': 0.579859078}\n",
      "\n",
      "====================\n",
      "\n",
      "차입매수는 대상기업의 자산이나 부채를 지렛대로 하여 기업의 경쟁력을 회복하고 기업의 효율성을 제고시키는 유용한 기능이 있는 반면, 그 남용의 가능성 및 그로 인한 피해규모도 크기 때문에, 위와 같이 미국 등 외국의 규제 및 대응방식도 다양하고 우리나라에서도 실무 및 학계에서 그 배임죄 성립 여부에 관하여 많은 논란을 야기하고 있다. 다. 배임죄 성립 여부 1) 담보제공형 차입매수의 경우 담보제공형 차입매수의 경우에 인수회사가 인수자금의 차입금을 변제하지 못할 위험이 있는 상태임에도 대상회사가 아무런 반대급부 없이 회사자산을 담보로 제공하는 것이 인수회사에게는 재산상 이익을 취득하게 하고 대상회사에 대하여는 손해 또는 손해발생의 위험을 초래하는 것으로 볼 것인지 여부에 따라 배임죄의 성립 여부가 좌우된다. 판례(이하 ‘신한 LBO사건’이라 함)는 손해발생의 위험을 초래한 경우도 배임죄의 성립요건인 ‘손해를 가한 때’에 포함된다는 위험범설의 입장에서, 인수회사가 대상회사의 담보제공으로 인한 위험부담에 상응하는 반대급부를 제공하지 아니한 이상, 그 담보제공시 담보가치에 상응하는 재산상 손해발생의 위험을 가한 것이라고 판시함으로써 배임죄의 성립을 긍정하였다. 신한 LBO사건에서는 인수회사인 SPC의 인수자금은 대상회사의 신주 납입금으로 대상회사에 입금되어 회사의 채무변제에 사용되거나 대상회사의 채무를 인수하는 데에 사용되었지만 SPC의 인수자금 대출로 인한 직접적 이득은 대상회사에 귀속된다고 할 수 없고 SPC의 이익을 위한 행위로서 위 담보제공의 반대급부로 볼 수 없다고 판시하였다. 만약 인수회사가 차입금이 상환될 때까지 인수 주식·채권 등을 대출 금융기관이나 대상회사에 별도의 담보로 제공한 경우라 하더라도 마찬가지라는 것이다. 신한 LBO사건의 경우 인수인인 피고인이 대상회사의 대표이사로서 한 대상회사 재산 담보제공 행위는 대상회사와는 이해충돌이 되는 자기거래이므로 엄격한 공정성이 요구되는데, 담보제공과 등가성 있는 반대급부가 제공되지 않는 이상 공정성이 없어 이\n",
      "{'page': None, 'source': None, 'score': 0.574328423}\n",
      "\n",
      "====================\n",
      "\n",
      "차입매수는 대상기업의 자산이나 부채를 지렛대로 하여 기업의 경쟁력을 회복하고 기업의 효율성을 제고시키는 유용한 기능이 있는 반면, 그 남용의 가능성 및 그로 인한 피해규모도 크기 때문에, 위와 같이 미국 등 외국의 규제 및 대응방식도 다양하고 우리나라에서도 실무 및 학계에서 그 배임죄 성립 여부에 관하여 많은 논란을 야기하고 있다. 다. 배임죄 성립 여부 1) 담보제공형 차입매수의 경우 담보제공형 차입매수의 경우에 인수회사가 인수자금의 차입금을 변제하지 못할 위험이 있는 상태임에도 대상회사가 아무런 반대급부 없이 회사자산을 담보로 제공하는 것이 인수회사에게는 재산상 이익을 취득하게 하고 대상회사에 대하여는 손해 또는 손해발생의 위험을 초래하는 것으로 볼 것인지 여부에 따라 배임죄의 성립 여부가 좌우된다. 판례(이하 ‘신한 LBO사건’이라 함)는 손해발생의 위험을 초래한 경우도 배임죄의 성립요건인 ‘손해를 가한 때’에 포함된다는 위험범설의 입장에서, 인수회사가 대상회사의 담보제공으로 인한 위험부담에 상응하는 반대급부를 제공하지 아니한 이상, 그 담보제공시 담보가치에 상응하는 재산상 손해발생의 위험을 가한 것이라고 판시함으로써 배임죄의 성립을 긍정하였다. 신한 LBO사건에서는 인수회사인 SPC의 인수자금은 대상회사의 신주 납입금으로 대상회사에 입금되어 회사의 채무변제에 사용되거나 대상회사의 채무를 인수하는 데에 사용되었지만 SPC의 인수자금 대출로 인한 직접적 이득은 대상회사에 귀속된다고 할 수 없고 SPC의 이익을 위한 행위로서 위 담보제공의 반대급부로 볼 수 없다고 판시하였다. 만약 인수회사가 차입금이 상환될 때까지 인수 주식·채권 등을 대출 금융기관이나 대상회사에 별도의 담보로 제공한 경우라 하더라도 마찬가지라는 것이다. 신한 LBO사건의 경우 인수인인 피고인이 대상회사의 대표이사로서 한 대상회사 재산 담보제공 행위는 대상회사와는 이해충돌이 되는 자기거래이므로 엄격한 공정성이 요구되는데, 담보제공과 등가성 있는 반대급부가 제공되지 않는 이상 공정성이 없어 이\n",
      "{'page': None, 'source': None, 'score': 0.574328423}\n",
      "\n",
      "====================\n",
      "\n",
      "(가) 공개매수에 의한 출자. 다만 외국기업이 발행한 주권을 대상으로 하는 외국법률에 의한 공개매수의 경우에는 해당 국가에서 공개매수신고서 또는 이에 준하는 서류를 제출하는 때에 이를 신고하여야 한다. (나) 금융기관(금융위원회법 제38조 각 호의 어느 하나에 해당하는 기관)의 단기매매 증권의 취득·처분(담보권 등 권리실행에 의한 출자·출자지분 처분을 포함) (4) 자기자본의 100분의 5(대규모법인의 경우 1,000분의 25) 이상을 출자(최근 사업연도말 재무상태표상의 가액을 기준으로 한다)하고 있는 주권비상장법인(코스닥시장상장법인을 포함)이 제3호 나목 (1)부터 (3)까지의 어느 하나에 해당된 사실이 확인된 때다. 해당 주권상장법인의 채권·채무에 관한 다음의 어느 하나에 해당하는 사실 또는 결정이 있은 때 (1) 자기자본의 100분의 10(대규모법인의 경우 100분의 5) 이상에 해당하는 단기차입금의 증가에 관한 결정이 있은 때. 이 경우 단기차입금에는 모집 외의 방법으로 발행되는 만기 1년 이내의 사채금액을 포함하며, 기존의 단기차입금 상환을 위한 차입금은 제외한다. (2) 자기자본의 100분의 5(대규모법인의 경우 1,000분의 25) 이상의 채무를 인수하거나 면제하여 주기로 결정한 때 (3) 자기자본의 100분의 5(대규모법인의 경우 1,000분의 25) 이상의 담보제공(타인을 위하여 담보를 제공하는 경우에 한한다. 이하 같다) 또는 채무보증(입찰·계약·하자·차액 보증 등의 이행보증과 납세보증은 제외한다. 이하 같다)에 관한 결정이 있은 때. 이 경우 그 결정일 또는 사유발생일 현재의 채무자별 담보제공 또는 채무보증 잔액을 함께 신고하여야 한다. (4) 제2호 다목 (3)에 해당하는 채무자가 제3호나목(1)부터 (3)까지의 어느 하나에 해당된 사실이 확인된 때 (5) 발행한 사채와 관련하여 자기자본의 100분의 5(대규모법인의 경우 1,000분의 25) 이상의 금액에 상당하는 원리금의 지급을 이행하지 못한 때. 이 경우 신고금액의 산정은 해당 사업연\n",
      "{'page': None, 'source': None, 'score': 0.564918}\n",
      "\n",
      "====================\n",
      "\n",
      "(라) 발행 예외 공사는 ⅰ) 금리변동 등 경제환경의 변화로 인한 손실로 자기자본의 급격한 감소가 예상된다고 위원회가 인정하는 경우(제1호), ⅱ) 대출금의 조기상환·부실화 등 대통령령으로 정하는 사유가 발생한 경우(제2호)에는 주택저당채권담보부채권 또는 주택저당증권을 발행하여서는 아니 된다(법33).위 제2호에서 “대통령령으로 정하는 사유”란 다음의 어느 하나에 해당하는 사유를 말한다(영19).1. 채무자가 주택저당채권을 만기 전에 상환하거나 그 밖의 사유로 주택저당채권이 소멸된 경우2. 채무자의 채무불이행으로 채권자가 저당권(근저당권 포함)을 행사하거나, 저당권이 설정된 주택이 멸실되는 등의 사유로 저당권이 소멸된 경우3. 주택저당채권의 채무자가 금융거래 등 상거래에서 약정한 기일 내에 채무를 변제하지 아니한 자로서 금융위원회가 정하는 자인 경우4. 주택저당채권이나 이를 담보하는 저당권이 설정된 주택과 관련하여 가압류·압류·체납처분 또는 가처분의 결정이 있는 경우3. 주택금융 신용보증(1) 신용보증의 개념“신용보증”이란 공사가 다음의 어느 하나의 경우에 발생하는 채무를 주택금융신용보증기금[주택담보노후연금보증 계정(“계정”)은 제외]의 부담으로 보증하는 행위를 말한다(법2(8)).가. 주택수요자(외국법에 따라 외국에 영주할 수 있는 권리를 가진 사람을 제외한 대한민국 국민만 해당)가 주택을 건축·구입·임차(전세 포함) 또는 개량하거나 이에 들어간 자금을 보전하기 위하여 금융기관으로부터 대출을 받는 경우나. 준주택수요자(외국법에 따라 외국에 영주할 수 있는 권리를 가진 사람을 제외한 대한민국 국민만 해당)가 주택법에 따른 준주택(소득세법에 따른 고가주택의 기준에 해당하지 아니하는 준주택 중 대통령령으로 정하는 준주택에 한한다)을 주거목적으로 구입·임차(전세 포함) 또는 개량하거나 이에 들어간 자금을 보전하기 위하여 금융기관으로부터 대출을 받는 경우다. 주택사업자가 주택수요자에게 분양하거나 임대할 목적으로 주택을 건설하거나 구입하기 위하여 금융기관으로부터 대출을\n",
      "{'page': None, 'source': None, 'score': 0.56223619}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\"차입금\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rerank_documents]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 실행 결과\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m search_results \u001b[38;5;241m=\u001b[39m \u001b[43mpinecone_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m환경\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-reranker-v2-m3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-TNmHyL-r-py3.11/lib/python3.11/site-packages/langchain_core/retrievers.py:252\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    251\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    255\u001b[0m         result,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-TNmHyL-r-py3.11/lib/python3.11/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 245\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-TNmHyL-r-py3.11/lib/python3.11/site-packages/langchain_teddynote/community/pinecone.py:376\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **search_kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Rerank 옵션이 있는 경우 rerank 수행\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrerank\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    375\u001b[0m ):\n\u001b[0;32m--> 376\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rerank_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-TNmHyL-r-py3.11/lib/python3.11/site-packages/langchain_teddynote/community/pinecone.py:499\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._rerank_documents\u001b[0;34m(self, query, documents, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m top_n \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(documents))\n\u001b[1;32m    495\u001b[0m rerank_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    496\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc\u001b[38;5;241m.\u001b[39mpage_content} \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents)\n\u001b[1;32m    497\u001b[0m ]\n\u001b[0;32m--> 499\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241m.\u001b[39mrerank(\n\u001b[1;32m    500\u001b[0m     model\u001b[38;5;241m=\u001b[39mrerank_model,\n\u001b[1;32m    501\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m    502\u001b[0m     documents\u001b[38;5;241m=\u001b[39mrerank_docs,\n\u001b[1;32m    503\u001b[0m     top_n\u001b[38;5;241m=\u001b[39mtop_n,\n\u001b[1;32m    504\u001b[0m     return_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    505\u001b[0m )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# 재정렬된 결과를 기반으로 문서 리스트 재구성\u001b[39;00m\n\u001b[1;32m    508\u001b[0m reranked_documents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Index' object has no attribute 'inference'"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\"환경\",search_kwargs={\"rerank\": True, \"rerank_model\": \"bge-reranker-v2-m3\", \"top_n\": 3})\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-TNmHyL-r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
